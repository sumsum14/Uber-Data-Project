{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>city</th>\n",
       "      <th>income</th>\n",
       "      <th>state</th>\n",
       "      <th>product</th>\n",
       "      <th>_id</th>\n",
       "      <th>temp</th>\n",
       "      <th>surge</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri, 20 Nov 2015 22:19:52 GMT</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>High</td>\n",
       "      <td>GA</td>\n",
       "      <td>UberSUV</td>\n",
       "      <td>b605b0b06730c256bc90499b6c53afaf</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 18 Nov 2015 17:54:37 GMT</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Low</td>\n",
       "      <td>GA</td>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>06acbfc4f40ff6cb6ef15a8755945079</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 18 Nov 2015 19:27:14 GMT</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>High</td>\n",
       "      <td>GA</td>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>8a45a65827191fa1ba23fdf767196104</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, 18 Nov 2015 23:12:56 GMT</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Middle</td>\n",
       "      <td>MA</td>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>f19996613c10c3bf40289591e13b9734</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat, 21 Nov 2015 02:21:21 GMT</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Low</td>\n",
       "      <td>DC</td>\n",
       "      <td>uberX</td>\n",
       "      <td>f5fd3879435d240acb5bbbe808caf81b</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time        city  income state    product                               _id  temp  surge        weather\n",
       "0  Fri, 20 Nov 2015 22:19:52 GMT     Atlanta    High    GA    UberSUV  b605b0b06730c256bc90499b6c53afaf    62     10          Clear\n",
       "1  Wed, 18 Nov 2015 17:54:37 GMT     Atlanta     Low    GA  UberBLACK  06acbfc4f40ff6cb6ef15a8755945079    66     10           Rain\n",
       "2  Wed, 18 Nov 2015 19:27:14 GMT     Atlanta    High    GA  UberBLACK  8a45a65827191fa1ba23fdf767196104    69     10           Rain\n",
       "3  Wed, 18 Nov 2015 23:12:56 GMT      Boston  Middle    MA  UberBLACK  f19996613c10c3bf40289591e13b9734    40     10  Partly Cloudy\n",
       "4  Sat, 21 Nov 2015 02:21:21 GMT  Washington     Low    DC      uberX  f5fd3879435d240acb5bbbe808caf81b    48     10          Clear"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"output.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to put full name of Day\n",
    "def day_fix(string):\n",
    "    if string == 'Mon':\n",
    "        return \"Monday\"\n",
    "    elif string =='Tue':\n",
    "        return \"Tuesday\"\n",
    "    elif string =='Wed':\n",
    "        return \"Wednesday\"\n",
    "    elif string =='Thu':\n",
    "        return 'Thursday'\n",
    "    elif string == 'Fri':\n",
    "        return 'Friday'\n",
    "    elif string == 'Sat':\n",
    "        return 'Saturday'\n",
    "    elif string == 'Sun':\n",
    "        return 'Sunday'\n",
    "    else:\n",
    "        print \"Error in day_fix!!!!!\"\n",
    "\n",
    "# Function to round everything **Down** to the nearest 10 minutes\n",
    "def min_fix(string):\n",
    "    num = int(string)\n",
    "    return str(num - (num%10))\n",
    "\n",
    "# Check and replace the surge\n",
    "def surge_check(surge):\n",
    "    if surge == 10:\n",
    "        return \"No Surge\"\n",
    "    elif surge > 15:\n",
    "        return \"High Surge\"\n",
    "    elif surge == 15:\n",
    "        return \"Mid Surge\"\n",
    "    else:\n",
    "        return \"Low Surge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After messing with the data, found that only a small percentage of the data has a Surge (only 5.6%). After digging deeper into the surge prices and messing around with different combinations I set the limits at **Low Surge < 1.5x**, **Mid Surge = 1.5x**, and **High Surge > 1.5x**. I thought that is a fair cut off as well because you are spending 50% more on the ride at 1.5x surge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code to extract Weekdays and time of day from given dataframe\n",
    "time_list = [df.time[index].split(' ') for index in df.index]\n",
    "weekday_list = []\n",
    "hour_list = []\n",
    "for row in range(len(time_list)):\n",
    "    time_list[row].remove('GMT')\n",
    "    time_list[row][0] = time_list[row][0].replace(',','')\n",
    "    time_list[row][0] = day_fix(time_list[row][0])\n",
    "    weekday_list.append(time_list[row][0])\n",
    "    hour_list.append(time_list[row][4][0:2] + ':' + min_fix(time_list[row][4][3:5]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to create Surge levels\n",
    "surge_list = [surge_check(df.surge[index]) for index in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to convert Temp to ints\n",
    "temperature_list = [int(df.temp[index]) for index in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Code to clean cartype\n",
    "for index in df.index:\n",
    "    if df.loc[index,'product'] == 'uberX + Car Seat':\n",
    "        df.loc[index,'product'] = 'uberX'\n",
    "    elif df.loc[index,'product'] == 'SUV + Car Seat':\n",
    "        df.loc[index,'product'] = 'UberSUV'\n",
    "    elif df.loc[index,'product'] == 'BLACK CAR + Car Seat':\n",
    "        df.loc[index,'product'] = 'UberBlack'\n",
    "    elif df.loc[index,'product'] == 'UberSELECT':\n",
    "        df.loc[index,'product'] = 'uberSELECT'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cartype</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>surge</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>weather</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UberSUV</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>b605b0b06730c256bc90499b6c53afaf</td>\n",
       "      <td>High</td>\n",
       "      <td>No Surge</td>\n",
       "      <td>62</td>\n",
       "      <td>22:10</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>06acbfc4f40ff6cb6ef15a8755945079</td>\n",
       "      <td>Low</td>\n",
       "      <td>No Surge</td>\n",
       "      <td>66</td>\n",
       "      <td>17:50</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>8a45a65827191fa1ba23fdf767196104</td>\n",
       "      <td>High</td>\n",
       "      <td>No Surge</td>\n",
       "      <td>69</td>\n",
       "      <td>19:20</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UberBLACK</td>\n",
       "      <td>Boston</td>\n",
       "      <td>f19996613c10c3bf40289591e13b9734</td>\n",
       "      <td>Middle</td>\n",
       "      <td>No Surge</td>\n",
       "      <td>40</td>\n",
       "      <td>23:10</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uberX</td>\n",
       "      <td>Washington</td>\n",
       "      <td>f5fd3879435d240acb5bbbe808caf81b</td>\n",
       "      <td>Low</td>\n",
       "      <td>No Surge</td>\n",
       "      <td>48</td>\n",
       "      <td>02:20</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cartype        city                                id  income     surge  temperature   time        weather    weekday\n",
       "0    UberSUV     Atlanta  b605b0b06730c256bc90499b6c53afaf    High  No Surge           62  22:10          Clear     Friday\n",
       "1  UberBLACK     Atlanta  06acbfc4f40ff6cb6ef15a8755945079     Low  No Surge           66  17:50           Rain  Wednesday\n",
       "2  UberBLACK     Atlanta  8a45a65827191fa1ba23fdf767196104    High  No Surge           69  19:20           Rain  Wednesday\n",
       "3  UberBLACK      Boston  f19996613c10c3bf40289591e13b9734  Middle  No Surge           40  23:10  Partly Cloudy  Wednesday\n",
       "4      uberX  Washington  f5fd3879435d240acb5bbbe808caf81b     Low  No Surge           48  02:20          Clear   Saturday"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Final Dataframe for use\n",
    "dict_final = {'id': df._id, 'surge': surge_list , 'temperature': temperature_list, 'weather': df.weather,\n",
    "             'cartype': df['product'], 'city': df.city, 'income': df.income, 'weekday': weekday_list, \n",
    "              'time': hour_list}\n",
    "df_final = pd.DataFrame(dict_final)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data that has surge 0.056\n",
      "Percentage of Surge that has Low Surge 0.370\n",
      "Percentage of Surge that has High Surge 0.291\n",
      "Percentage of Surge that has Mid Surge 0.339\n"
     ]
    }
   ],
   "source": [
    "# Code to test No Surge vs Low Surge vs. High Surge\n",
    "\n",
    "count_nosurge = df['surge'] == 10\n",
    "count_surge = df['surge'] != 10\n",
    "surgedf = df[count_surge]\n",
    "\n",
    "count_highsurge = df['surge'] > 15\n",
    "count_lowsurge = surgedf['surge'] < 15\n",
    "count_midsurge = surgedf['surge'] == 15\n",
    "\n",
    "print 'Percentage of data that has surge %0.3f' % (float(sum(count_surge))/len(df_final))\n",
    "print 'Percentage of Surge that has Low Surge %0.3f' % (float(sum(count_lowsurge))/sum(count_surge))\n",
    "print 'Percentage of Surge that has High Surge %0.3f' % ((float(sum(count_highsurge))/sum(count_surge)))\n",
    "print 'Percentage of Surge that has Mid Surge %0.3f' % (float(sum(count_midsurge))/sum(count_surge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training and test data\n",
    "itrain, itest = train_test_split(xrange(df_final.shape[0]), train_size=0.7)\n",
    "\n",
    "mask=np.ones(df_final.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)\n",
    "\n",
    "#split training set into validation set if needed (not ended up needed)\n",
    "itrain, itest = train_test_split(xrange(df_final[mask].shape[0]), train_size=0.7)\n",
    "\n",
    "mask2 = np.ones(df_final[mask].shape[0], dtype = 'int')\n",
    "mask2[itrain] = 1\n",
    "mask2[itest] = 0\n",
    "mask2 = (mask2==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clear' 'Rain' 'Partly Cloudy' 'Overcast' 'Mostly Cloudy'\n",
      " 'Scattered Clouds' 'Light Rain']\n",
      "['UberSUV' 'UberBLACK' 'uberX' 'uberXL' 'uberWAV' 'uberTAXI' 'uberSELECT'\n",
      " 'WAV' 'uberFAMILY' 'uberT' 'UberBlack' 'ASSIST' 'Yellow WAV']\n",
      "['Atlanta' 'Boston' 'Washington' 'New York' 'San Francisco']\n",
      "142\n",
      "<type 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "#Check data cleaning\n",
    "print df_final['weather'].unique()\n",
    "print df_final['cartype'].unique()\n",
    "print df_final['city'].unique()\n",
    "print len(df_final['time'].unique())\n",
    "print type(df_final['temperature'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cartype=ASSIST</th>\n",
       "      <th>cartype=UberBLACK</th>\n",
       "      <th>cartype=UberBlack</th>\n",
       "      <th>cartype=UberSUV</th>\n",
       "      <th>cartype=WAV</th>\n",
       "      <th>cartype=Yellow WAV</th>\n",
       "      <th>cartype=uberFAMILY</th>\n",
       "      <th>cartype=uberSELECT</th>\n",
       "      <th>cartype=uberT</th>\n",
       "      <th>cartype=uberTAXI</th>\n",
       "      <th>cartype=uberWAV</th>\n",
       "      <th>cartype=uberX</th>\n",
       "      <th>cartype=uberXL</th>\n",
       "      <th>city=Atlanta</th>\n",
       "      <th>city=Boston</th>\n",
       "      <th>city=New York</th>\n",
       "      <th>city=San Francisco</th>\n",
       "      <th>city=Washington</th>\n",
       "      <th>income=High</th>\n",
       "      <th>income=Low</th>\n",
       "      <th>income=Middle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time=00:0</th>\n",
       "      <th>time=00:10</th>\n",
       "      <th>time=00:20</th>\n",
       "      <th>time=00:30</th>\n",
       "      <th>time=00:40</th>\n",
       "      <th>time=00:50</th>\n",
       "      <th>time=01:0</th>\n",
       "      <th>time=01:10</th>\n",
       "      <th>time=01:20</th>\n",
       "      <th>time=01:30</th>\n",
       "      <th>time=01:40</th>\n",
       "      <th>time=01:50</th>\n",
       "      <th>time=02:0</th>\n",
       "      <th>time=02:10</th>\n",
       "      <th>time=02:20</th>\n",
       "      <th>time=02:30</th>\n",
       "      <th>time=02:40</th>\n",
       "      <th>time=02:50</th>\n",
       "      <th>time=03:0</th>\n",
       "      <th>time=03:10</th>\n",
       "      <th>time=03:20</th>\n",
       "      <th>time=03:30</th>\n",
       "      <th>time=03:40</th>\n",
       "      <th>time=03:50</th>\n",
       "      <th>time=04:0</th>\n",
       "      <th>time=04:10</th>\n",
       "      <th>time=04:20</th>\n",
       "      <th>time=04:30</th>\n",
       "      <th>...</th>\n",
       "      <th>time=17:40</th>\n",
       "      <th>time=17:50</th>\n",
       "      <th>time=18:0</th>\n",
       "      <th>time=18:10</th>\n",
       "      <th>time=18:20</th>\n",
       "      <th>time=18:30</th>\n",
       "      <th>time=18:40</th>\n",
       "      <th>time=18:50</th>\n",
       "      <th>time=19:0</th>\n",
       "      <th>time=19:10</th>\n",
       "      <th>time=19:20</th>\n",
       "      <th>time=19:30</th>\n",
       "      <th>time=19:40</th>\n",
       "      <th>time=19:50</th>\n",
       "      <th>time=20:0</th>\n",
       "      <th>time=20:10</th>\n",
       "      <th>time=20:20</th>\n",
       "      <th>time=20:30</th>\n",
       "      <th>time=20:40</th>\n",
       "      <th>time=20:50</th>\n",
       "      <th>time=21:0</th>\n",
       "      <th>time=21:10</th>\n",
       "      <th>time=21:20</th>\n",
       "      <th>time=21:30</th>\n",
       "      <th>time=21:40</th>\n",
       "      <th>time=21:50</th>\n",
       "      <th>time=22:0</th>\n",
       "      <th>time=22:10</th>\n",
       "      <th>time=22:20</th>\n",
       "      <th>time=22:30</th>\n",
       "      <th>time=22:40</th>\n",
       "      <th>time=22:50</th>\n",
       "      <th>time=23:0</th>\n",
       "      <th>time=23:10</th>\n",
       "      <th>time=23:20</th>\n",
       "      <th>time=23:30</th>\n",
       "      <th>time=23:40</th>\n",
       "      <th>time=23:50</th>\n",
       "      <th>weather=Clear</th>\n",
       "      <th>weather=Light Rain</th>\n",
       "      <th>weather=Mostly Cloudy</th>\n",
       "      <th>weather=Overcast</th>\n",
       "      <th>weather=Partly Cloudy</th>\n",
       "      <th>weather=Rain</th>\n",
       "      <th>weather=Scattered Clouds</th>\n",
       "      <th>weekday=Friday</th>\n",
       "      <th>weekday=Saturday</th>\n",
       "      <th>weekday=Thursday</th>\n",
       "      <th>weekday=Tuesday</th>\n",
       "      <th>weekday=Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cartype=ASSIST  cartype=UberBLACK  cartype=UberBlack  cartype=UberSUV  cartype=WAV  cartype=Yellow WAV  cartype=uberFAMILY  cartype=uberSELECT  cartype=uberT  cartype=uberTAXI  cartype=uberWAV  cartype=uberX  cartype=uberXL  city=Atlanta  city=Boston  city=New York  city=San Francisco  city=Washington  income=High  income=Low  income=Middle  temperature  time=00:0  time=00:10  time=00:20  time=00:30  time=00:40  time=00:50  time=01:0  time=01:10  time=01:20  time=01:30  time=01:40  \\\n",
       "0               0                  0                  0                1            0                   0                   0                   0              0                 0                0              0               0             1            0              0                   0                0            1           0              0           62          0           0           0           0           0           0          0           0           0           0           0   \n",
       "1               0                  1                  0                0            0                   0                   0                   0              0                 0                0              0               0             1            0              0                   0                0            0           1              0           66          0           0           0           0           0           0          0           0           0           0           0   \n",
       "2               0                  1                  0                0            0                   0                   0                   0              0                 0                0              0               0             1            0              0                   0                0            1           0              0           69          0           0           0           0           0           0          0           0           0           0           0   \n",
       "3               0                  1                  0                0            0                   0                   0                   0              0                 0                0              0               0             0            1              0                   0                0            0           0              1           40          0           0           0           0           0           0          0           0           0           0           0   \n",
       "4               0                  0                  0                0            0                   0                   0                   0              0                 0                0              1               0             0            0              0                   0                1            0           1              0           48          0           0           0           0           0           0          0           0           0           0           0   \n",
       "\n",
       "   time=01:50  time=02:0  time=02:10  time=02:20  time=02:30  time=02:40  time=02:50  time=03:0  time=03:10  time=03:20  time=03:30  time=03:40  time=03:50  time=04:0  time=04:10  time=04:20  time=04:30        ...          time=17:40  time=17:50  time=18:0  time=18:10  time=18:20  time=18:30  time=18:40  time=18:50  time=19:0  time=19:10  time=19:20  time=19:30  time=19:40  time=19:50  time=20:0  time=20:10  time=20:20  time=20:30  time=20:40  time=20:50  time=21:0  time=21:10  time=21:20  \\\n",
       "0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0        ...                   0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0   \n",
       "1           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0        ...                   0           1          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0   \n",
       "2           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0        ...                   0           0          0           0           0           0           0           0          0           0           1           0           0           0          0           0           0           0           0           0          0           0           0   \n",
       "3           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0        ...                   0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0   \n",
       "4           0          0           0           1           0           0           0          0           0           0           0           0           0          0           0           0           0        ...                   0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0          0           0           0   \n",
       "\n",
       "   time=21:30  time=21:40  time=21:50  time=22:0  time=22:10  time=22:20  time=22:30  time=22:40  time=22:50  time=23:0  time=23:10  time=23:20  time=23:30  time=23:40  time=23:50  weather=Clear  weather=Light Rain  weather=Mostly Cloudy  weather=Overcast  weather=Partly Cloudy  weather=Rain  weather=Scattered Clouds  weekday=Friday  weekday=Saturday  weekday=Thursday  weekday=Tuesday  weekday=Wednesday  \n",
       "0           0           0           0          0           1           0           0           0           0          0           0           0           0           0           0              1                   0                      0                 0                      0             0                         0               1                 0                 0                0                  0  \n",
       "1           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0              0                   0                      0                 0                      0             1                         0               0                 0                 0                0                  1  \n",
       "2           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0              0                   0                      0                 0                      0             1                         0               0                 0                 0                0                  1  \n",
       "3           0           0           0          0           0           0           0           0           0          0           1           0           0           0           0              0                   0                      0                 0                      1             0                         0               0                 0                 0                0                  1  \n",
       "4           0           0           0          0           0           0           0           0           0          0           0           0           0           0           0              1                   0                      0                 0                      0             0                         0               0                 1                 0                0                  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the X matrix\n",
    "Xvec_list = []\n",
    "for i in range(len(df)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['city'] = dict_final['city'][i]\n",
    "    temp_dict['cartype'] = dict_final['cartype'][i]\n",
    "    temp_dict['income'] = dict_final['income'][i]\n",
    "    temp_dict['temperature'] = dict_final['temperature'][i]\n",
    "    temp_dict['time'] = dict_final['time'][i]\n",
    "    temp_dict['weather'] = dict_final['weather'][i]\n",
    "    temp_dict['weekday'] = dict_final['weekday'][i]\n",
    "    Xvec_list.append(temp_dict)\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vec.fit_transform(Xvec_list)\n",
    "fcolumns = vec.get_feature_names()\n",
    "data = vec.fit_transform(Xvec_list).toarray()\n",
    "X_final = pd.DataFrame(data = data, columns = fcolumns)\n",
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surge=High Surge</th>\n",
       "      <th>surge=Low Surge</th>\n",
       "      <th>surge=Mid Surge</th>\n",
       "      <th>surge=No Surge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surge=High Surge  surge=Low Surge  surge=Mid Surge  surge=No Surge\n",
       "0                 0                0                0               1\n",
       "1                 0                0                0               1\n",
       "2                 0                0                0               1\n",
       "3                 0                0                0               1\n",
       "4                 0                0                0               1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the Y matrix\n",
    "Yvec_list = []\n",
    "for i in range(len(df)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['surge'] = dict_final['surge'][i]\n",
    "    Yvec_list.append(temp_dict)\n",
    "\n",
    "vec2 = DictVectorizer()\n",
    "vec2.fit_transform(Yvec_list)\n",
    "columns = vec2.get_feature_names()\n",
    "data = vec2.fit_transform(Yvec_list).toarray()\n",
    "Y_final = pd.DataFrame(data = data, columns = columns)\n",
    "Y_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "X = X_final[mask]\n",
    "Y = Y_final[mask]\n",
    "X_train = X[mask2]\n",
    "Y_train = Y[mask2]\n",
    "X_Val = X[~mask2]\n",
    "Y_Val = Y[~mask2]\n",
    "X_test = X_final[~mask]\n",
    "Y_test = Y_final[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use cv_optimize writen in hw3\n",
    "def cv_optimize(clf, parameters, X, y, n_folds= 5, score_func= None):\n",
    "    clftemp = GridSearchCV(clf, parameters, cv = n_folds, score_func=score_func )\n",
    "    clftemp.fit(X, y)\n",
    "    best = clftemp.best_estimator_\n",
    "    params = clftemp.best_params_\n",
    "    print best\n",
    "    return best, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter dictionary to be passed into cv_optimize\n",
    "parameters_dict = {}\n",
    "parameters_dict['max_features'] = ['auto', 'sqrt', 'log2', None]\n",
    "parameters_dict['class_weight'] = ['auto', 'subsample']\n",
    "parameters_dict['max_depth'] = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='subsample',\n",
      "            criterion='gini', max_depth=None, max_features='sqrt',\n",
      "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "#optimize the best predictor for random forest\n",
    "%%time\n",
    "rf = RandomForestClassifier(oob_score = True)\n",
    "rf2, rf2params = cv_optimize(rf,parameters_dict, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'subsample', 'max_depth': None, 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best predictor\n",
    "rf2 = RandomForestClassifier(class_weight = rf2params['class_weight'],\n",
    "                             max_depth = rf2params['max_depth'], max_features = rf2params['max_features'])\n",
    "rf2params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#See how prediction evolves over the amount of trees in random forest\n",
    "#note: will always increase with more trees, but reaches a \"limit\" where it just takes forever to train the model,\n",
    "#so pick a place where this is optimal by a time prespective\n",
    "\n",
    "num_trees = range(10,110,10)\n",
    "scores = []\n",
    "for i in range(len(num_trees)):\n",
    "    rf2 = RandomForestClassifier(n_estimators = num_trees[i],\n",
    "                                 class_weight = rf2params['class_weight'], \n",
    "                                 max_depth = rf2params['max_depth'])\n",
    "    rf2.fit(X,Y)\n",
    "    scores.append(rf2.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAI9CAYAAADo/+02AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAKZHsAEAAABgev8PQ0G9p5HhhI0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b61da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show plot of error and number of trees in classifier\n",
    "plt.plot(scores)\n",
    "plt.xticks(np.arange(10),num_trees)\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.title('Error by Number of Classification Trees')\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945236737022\n",
      "0.976392284705\n"
     ]
    }
   ],
   "source": [
    "#check the score on the test set for overfitting\n",
    "rf2 = RandomForestClassifier(n_estimators = 90,\n",
    "                             class_weight = rf2params['class_weight'], \n",
    "                             max_depth = rf2params['max_depth'])\n",
    "rf2.fit(X,Y)\n",
    "print rf2.score(X_test,Y_test)\n",
    "print rf2.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13244613959440943"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw0AAAIbCAYAAACpGXLSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIpLEooGIiIiIiCT9AWsR4q0256WOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x39960198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the feature importances\n",
    "features = rf2.feature_importances_\n",
    "plt.bar(np.arange(len(features)),features)\n",
    "max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]), array([[ 0.98888889,  0.01111111],\n",
       "        [ 0.95555556,  0.04444444],\n",
       "        [ 1.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 1.        ,  0.        ],\n",
       "        [ 1.        ,  0.        ],\n",
       "        [ 1.        ,  0.        ]]), array([[ 0.01111111,  0.98888889],\n",
       "        [ 0.04444444,  0.95555556],\n",
       "        [ 0.        ,  1.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  1.        ],\n",
       "        [ 0.        ,  1.        ],\n",
       "        [ 0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.132446139594\n",
      "temperature\n",
      "0.0249602013453\n",
      "time=23:20\n"
     ]
    }
   ],
   "source": [
    "#Temperature seems to be the best predictor at this point\n",
    "print features[21]\n",
    "print fcolumns[21]\n",
    "print features[12]\n",
    "print fcolumns[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    No Surge\n",
       "2    No Surge\n",
       "3    No Surge\n",
       "4    No Surge\n",
       "5    No Surge\n",
       "Name: surge, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the Y variable for Logistic Regression\n",
    "df_final['surge'].head()\n",
    "Y_lreg = df_final['surge'][mask]\n",
    "Y_lregtest = df_final['surge'][~mask]\n",
    "Y_lreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters to be tested for Logistic Regression\n",
    "lreg_paramdict = {}\n",
    "lreg_paramdict['C'] = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "lreg_paramdict['penalty'] = ['l1','l2']\n",
    "lreg_paramdict['multi_class'] = ['multinomial']\n",
    "lreg_paramdict['class_weight'] = ['auto',None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          penalty='l1', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0)\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "# optimize parameters for logistic regression\n",
    "%%time\n",
    "lreg = LogisticRegression(solver ='lbfgs' )\n",
    "lreg2, lregparams = cv_optimize(lreg,lreg_paramdict, X, Y_lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943520782396\n",
      "0.943905685492\n"
     ]
    }
   ],
   "source": [
    "lreg2 = LogisticRegression(solver ='lbfgs', C = lregparams['C'], class_weight = lregparams['class_weight'],\n",
    "                           multi_class = lregparams['multi_class'], penalty = lregparams['penalty'] )\n",
    "lreg2.fit(X,Y_lreg)\n",
    "print lreg2.score(X,Y_lreg)\n",
    "print lreg2.score(X_test,Y_lregtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06512861,  0.07213785,  0.26785431,  0.59487922],\n",
       "       [ 0.10195074,  0.25118669,  0.13596034,  0.51090223],\n",
       "       [ 0.06151384,  0.18257045,  0.16600788,  0.58990784],\n",
       "       ..., \n",
       "       [ 0.08125689,  0.19223633,  0.17188388,  0.55462289],\n",
       "       [ 0.094474  ,  0.14031953,  0.17538646,  0.58982001],\n",
       "       [ 0.03528186,  0.14078205,  0.12769427,  0.69624182]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017789825312028107"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg2.coef_[3][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model.logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.feature_selection.from_model._LearntSelectorMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr' and uses the\n",
      " |  cross-entropy loss, if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs' and\n",
      " |  'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  `liblinear` library, newton-cg and lbfgs solvers. It can handle both\n",
      " |  dense and sparse input. Use C-ordered arrays or CSR matrices containing\n",
      " |  64-bit floats for optimal performance; any other input format will be\n",
      " |  converted (and copied).\n",
      " |  \n",
      " |  The newton-cg and lbfgs solvers support only L2 regularization with primal\n",
      " |  formulation. The liblinear solver supports both L1 and L2 regularization,\n",
      " |  with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2'\n",
      " |      Used to specify the norm used in the penalization. The newton-cg and\n",
      " |      lbfgs solvers support only l2 penalties.\n",
      " |  \n",
      " |  dual : bool\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  C : float, optional (default=1.0)\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default: 1\n",
      " |      Useful only if solver is liblinear.\n",
      " |      when self.fit_intercept is True, instance vector x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equals to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : {dict, 'auto'}, optional\n",
      " |      Over-/undersamples the samples of each class according to the given\n",
      " |      weights. If not given, all classes are supposed to have weight one.\n",
      " |      The 'auto' mode selects weights inversely proportional to class\n",
      " |      frequencies in the training set.\n",
      " |  \n",
      " |  max_iter : int\n",
      " |      Useful only for the newton-cg and lbfgs solvers. Maximum number of\n",
      " |      iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  random_state : int seed, RandomState instance, or None (default)\n",
      " |      The seed of the pseudo random number generator to use when\n",
      " |      shuffling the data.\n",
      " |  \n",
      " |  solver : {'newton-cg', 'lbfgs', 'liblinear'}\n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |  tol : float, optional\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial'}\n",
      " |      Multiclass option can be either 'ovr' or 'multinomial'. If the option\n",
      " |      chosen is 'ovr', then a binary problem is fit for each label. Else\n",
      " |      the loss minimised is the multinomial loss fit across\n",
      " |      the entire probability distribution. Works only for the 'lbfgs'\n",
      " |      solver.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |  intercept_ : array, shape (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Maximum of the actual number of iterations across all classes.\n",
      " |      Valid only for the liblinear solver.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  sklearn.svm.LinearSVC : learns SVM models using the same algorithm.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  sklearn.linear_model.SGDClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.feature_selection.from_model._LearntSelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0)\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples in the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.from_model._LearntSelectorMixin:\n",
      " |  \n",
      " |  transform(self, X, threshold=None)\n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |      Uses ``coef_`` or ``feature_importances_`` to determine the most\n",
      " |      important features.  For models with a ``coef_`` for each class, the\n",
      " |      absolute sum over the classes is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array or scipy sparse matrix of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      threshold : string, float or None, optional (default=None)\n",
      " |          The threshold value to use for feature selection. Features whose\n",
      " |          importance is greater or equal are kept while the others are\n",
      " |          discarded. If \"median\" (resp. \"mean\"), then the threshold value is\n",
      " |          the median (resp. the mean) of the feature importances. A scaling\n",
      " |          factor (e.g., \"1.25*mean\") may also be used. If None and if\n",
      " |          available, the object attribute ``threshold`` is used. Otherwise,\n",
      " |          \"mean\" is used by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self: estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self: estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble.forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and use averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : integer, optional (default=10)\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=\"auto\")\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a percentage and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : integer or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |      Ignored if ``max_leaf_nodes`` is not None.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  min_samples_split : integer, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  min_samples_leaf : integer, optional (default=1)\n",
      " |      The minimum number of samples in newly created leaves.  A split is\n",
      " |      discarded if after the split, one of the leaves would contain less then\n",
      " |      ``min_samples_leaf`` samples.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the input samples required to be at a\n",
      " |      leaf node.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |      If not None then ``max_depth`` will be ignored.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  bootstrap : boolean, optional (default=True)\n",
      " |      Whether bootstrap samples are used when building trees.\n",
      " |  \n",
      " |  oob_score : bool\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization error.\n",
      " |  \n",
      " |  n_jobs : integer, optional (default=1)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      If -1, then the number of jobs is set to the number of cores.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity of the tree building process.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"auto\", \"subsample\" or None, optional\n",
      " |  \n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      The \"auto\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data.\n",
      " |  \n",
      " |      The \"subsample\" mode is the same as \"auto\" except that weights are\n",
      " |      computed based on the bootstrap sample for every tree grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |  \n",
      " |  oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      abc.NewBase\n",
      " |      BaseForest\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.feature_selection.from_model._LearntSelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the majority\n",
      " |      prediction of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest. The\n",
      " |      class probability of a single tree is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators]\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.from_model._LearntSelectorMixin:\n",
      " |  \n",
      " |  transform(self, X, threshold=None)\n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |      Uses ``coef_`` or ``feature_importances_`` to determine the most\n",
      " |      important features.  For models with a ``coef_`` for each class, the\n",
      " |      absolute sum over the classes is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array or scipy sparse matrix of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      threshold : string, float or None, optional (default=None)\n",
      " |          The threshold value to use for feature selection. Features whose\n",
      " |          importance is greater or equal are kept while the others are\n",
      " |          discarded. If \"median\" (resp. \"mean\"), then the threshold value is\n",
      " |          the median (resp. the mean) of the feature importances. A scaling\n",
      " |          factor (e.g., \"1.25*mean\") may also be used. If None and if\n",
      " |          available, the object attribute ``threshold`` is used. Otherwise,\n",
      " |          \"mean\" is used by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
